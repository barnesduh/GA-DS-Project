{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a bucket with 3 red balls and 7 blue balls in it. I reach into the bucket and grab a ball. What is the proability the ball is red, P(R)? The probability that it's blue, P(B)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of a red ball: 3 events/10 outcomes = .3\n",
    "Probability of a blue ball: 7 events/10 outcomes = .7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assume I have two buckets. Bucket 1, B1, have 5 red and 5 blue balls in it. Bucket 2, B2, has 2 red and 8 blue balls in it.\n",
    "\n",
    "*A) I first choose a bucket and then grab a ball. Assuming I choose bucket 1 and bucket 2 with equal probability, what is the probability that the chosen ball is red? blue?\n",
    "*B) What is the conditional probability that I choose a red ball given B1, P(R|B1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A) Indepdendent Probability: P(A,B) = P(A)P(B)\n",
    "    Probability Red = (5/10)(2/10)\n",
    "    Probability Red = (.5)(.2)\n",
    "    Probability Red = .1\n",
    "    Probability Blue = (5/10)(8/10)\n",
    "    Probability Blue = (.5)(.8)\n",
    "    Probability Blue = .4\n",
    "B) Conditional Probability: P(AB) = P(A|B)P(B)\n",
    "    Probability Red = (.1)(.3)\n",
    "    Probability Red = .03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we're performing a binary classification problem. We're given a binary class label y and a feature vector X with dimensionality m. Meaning there are m features.\n",
    "\n",
    "*A) What is Bayes theorem? Write it in terms of X and Y in the way it's used for our classification problem.\n",
    "*B) In this problem we have 4 probabilities, {P(X), P(Y), P(X|Y), P(Y|X)}, which ones do we need to estimate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) Bayes Theorem: P(Y|X1,...,Xm) = P(Y)P(X,1Y)*...*P(Xm1Y)\n",
    "    \n",
    "B) Probabilities Estimated: P(Y), P(X|Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the Naive Bayes assumption? Why do we need to make this assumption?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must assume independence since we have to estimate every possible combination of all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discussed the following 3 different Naive Bayes implementations in SKLearn. When would you use each?\n",
    "*Gaussian?\n",
    "*Bernoulli?\n",
    "*Multinomial?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gaussian is useful when the dataset is too large to call upon all at once and you must call upon it in chunks\n",
    "*Bernoulli is best used for data where there are multiple features, however each one is assumed to be binary valued. Can be used for word occurrence vector analysis\n",
    "*Multinomial can work with binary/boolean features and is often used on text data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of machine learning algorithm is logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In logistic regression we use the logistic function. What is the logistic function interpretted as?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic function allows us to make the S curve along which we can classify our data. Falling on one boundary or another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the assumption of logistic regression? What does the decision boundary look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assumptions are that it is a complete dataset, with independent observations that do not have linear relationships. Decisions boundaries can be both linear and non-linear, and is shaped off the observations you are building your model off of. The decision boundary is based off of the distance from one class to another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of algorithm is k-means clustering? Supervised or unsupervised?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does k-means clustering have any parameters? If so what are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. You must decide how many clusters you want to make. You can also decide how many iterations you want to one, define starting points, define distance for paramter clustering and more in scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the assumptions of k-means clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You assume there are K clusters and that variables have the same importance for every cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
